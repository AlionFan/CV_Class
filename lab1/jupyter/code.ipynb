{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算机视觉实验 1\n",
    "#### 任务概览\n",
    "1. 修改区域颜色\n",
    "2. 读取彩色图片创建掩码并按位与\n",
    "3. 形态学操作\n",
    "4. OCR文字识别\n",
    "5. 多人脸检测\n",
    "6. 基于 MeanShift 的目标跟踪\n",
    "7. 改进任务6\n",
    "8. 车道线检测\n",
    "\n",
    "-------附加题-------\n",
    "1. SIFT 特征匹配与图像拼接\n",
    "2. 细胞计数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务 1: 修改区域颜色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "# 读取彩色图像\n",
    "img = cv2.imread(\"lenacolor.png\") \n",
    "\n",
    "# 任务 1: 获取并打印左上角像素值\n",
    "\n",
    "# 任务 2: 修改图像左上角区域的颜色\n",
    "\n",
    "# 保存修改后的图像\n",
    "cv2.imwrite(\"modified_lenacolor.png\", img) \n",
    "\n",
    "# 任务 3: 获取并打印修改后的左上角像素值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务 2: 读取彩色图片创建掩码并按位与"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 读取彩色图像\n",
    "img = cv2.imread(\"x.jpg\") \n",
    "\n",
    "# 将图像从 BGR 转换为灰度并保存\n",
    "\n",
    "# 使用阈值处理创建二值掩码并保存\n",
    "\n",
    "# 根据掩码进行按位与操作并保存\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务 3: 形态学操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "# 使用 cv2.getStructuringElement 创建椭圆形核\n",
    "kernel = \n",
    "\n",
    "# --- 任务 1: 处理 4.jpg - 开运算和顶帽操作 ---\n",
    "img4 = cv2.imread(\"4.jpg\")  \n",
    "gray4 = cv2.cvtColor(img4, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 执行开运算，去除小亮点\n",
    "\n",
    "cv2.imwrite(\"open_4.jpg\", open4) \n",
    "\n",
    "# 执行顶帽操作，突出亮细节\n",
    "\n",
    "cv2.imwrite(\"tophat_4.jpg\", tophat4) \n",
    "\n",
    "# --- 任务 2: 处理 5.jpg - 形态学梯度操作 ---\n",
    "img5 = cv2.imread(\"5.jpg\") \n",
    "gray5 = cv2.cvtColor(img5, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# 执行形态学梯度操作，提取边缘\n",
    "\n",
    "cv2.imwrite(\"gradient_5.jpg\", gradient5)\n",
    "\n",
    "# --- 任务 3: 处理 6.jpg - 闭运算和黑帽操作 ---\n",
    "img6 = cv2.imread(\"6.jpg\")\n",
    "gray6 = cv2.cvtColor(img6, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 执行闭运算，填补小空洞\n",
    "\n",
    "cv2.imwrite(\"close_6.jpg\", close6)\n",
    "\n",
    "# 执行黑帽操作，突出暗细节\n",
    "\n",
    "cv2.imwrite(\"blackhat_6.jpg\", blackhat6) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务 4: OCR文字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import os\n",
    "\n",
    "def order_points(pts):\n",
    "    # 初始化一个坐标点数组，将按顺序排列\n",
    "    # 顺序为：左上、右上、右下、左下\n",
    "    \n",
    "\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # 获取有序的坐标点\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect  # 分别对应左上、右上、右下、左下\n",
    "\n",
    "    # 计算新图像的宽度\n",
    "    # 取底边和顶边的最大值作为宽度\n",
    "    \n",
    "    \n",
    "\n",
    "    # 计算新图像的高度\n",
    "    # 取右边和左边的最大值作为高度\n",
    "    \n",
    "    \n",
    "\n",
    "    # 定义变换后的目标坐标点\n",
    "    dst = np.array([\n",
    "        [0, 0],              # 左上\n",
    "        [maxWidth - 1, 0],   # 右上\n",
    "        [maxWidth - 1, maxHeight - 1],  # 右下\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")  # 左下\n",
    "\n",
    "    # 计算透视变换矩阵并应用变换\n",
    "\n",
    "\n",
    "    # 返回变换后的图像\n",
    "    return warped\n",
    "\n",
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    # 调整图像大小，保持宽高比\n",
    "    \n",
    "    \n",
    "    return resized\n",
    "\n",
    "# 主程序开始\n",
    "# 读取输入图像\n",
    "image = cv2.imread('receipt.jpg')\n",
    "# 计算缩放比例并保留原始图像副本\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "\n",
    "# 将图像调整到高度500像素\n",
    "image = resize(orig, height = 500)\n",
    "\n",
    "# 图像预处理\n",
    "# 转换为灰度图\n",
    "\n",
    "# 高斯模糊去噪\n",
    "\n",
    "# Canny边缘检测\n",
    "\n",
    "# 保存预处理结果\n",
    "print(\"STEP 1: 边缘检测\")\n",
    "cv2.imwrite(\"step1_image.jpg\", image)  # 保存原始调整大小后的图像\n",
    "cv2.imwrite(\"step1_edged.jpg\", edged)  # 保存边缘检测结果\n",
    "\n",
    "# 检测轮廓\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0]  # 查找所有轮廓\n",
    "\n",
    "# 按面积从大到小排序，取前5个轮廓\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "# 遍历轮廓寻找矩形\n",
    "for c in cnts:\n",
    "    # 计算轮廓周长\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    # 近似轮廓形状，epsilon为最大距离参数\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    # 如果找到4个顶点的轮廓，则认为是目标矩形\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "\n",
    "# 保存轮廓检测结果\n",
    "print(\"STEP 2: 获取轮廓\")\n",
    "cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)  # 在图像上绘制绿色轮廓\n",
    "cv2.imwrite(\"step2_outline.jpg\", image)  # 保存绘制轮廓后的图像\n",
    "\n",
    "# 执行透视变换\n",
    "# 将检测到的坐标点缩放回原始尺寸并进行变换\n",
    "\n",
    "\n",
    "# 对变换后的图像进行二值化处理\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)  # 转为灰度图\n",
    "ref = cv2.threshold(warped, 100, 255, cv2.THRESH_BINARY)[1]  # 二值化\n",
    "cv2.imwrite('scan.jpg', ref)  # 保存扫描结果\n",
    "\n",
    "# 保存变换结果\n",
    "print(\"STEP 3: 变换\")\n",
    "cv2.imwrite(\"step3_original.jpg\", resize(orig, height = 650))  # 保存原始图像\n",
    "cv2.imwrite(\"step3_scanned.jpg\", resize(ref, height = 650))    # 保存扫描结果\n",
    "\n",
    "# STEP 4: OCR文字识别\n",
    "print(\"STEP 4: OCR文字识别\")\n",
    "# 读取上一步的扫描结果\n",
    "image = cv2.imread('scan.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # 转换为灰度图\n",
    "\n",
    "# 选择预处理方法\n",
    "preprocess = 'blur'  # 可选 'thresh' 或 'blur'\n",
    "if preprocess == \"thresh\":\n",
    "    # 使用阈值进行二值化\n",
    "    gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "if preprocess == \"blur\":\n",
    "    # 使用中值模糊去噪\n",
    "    gray = cv2.medianBlur(gray, 3)\n",
    "\n",
    "# 将预处理后的灰度图临时保存为文件\n",
    "filename = \"{}.png\".format(os.getpid())\n",
    "cv2.imwrite(filename, gray)\n",
    "\n",
    "# 使用pytesseract进行OCR文字识别\n",
    "tessdata_config = '--tessdata-dir \"D:/Tesseract-OCR/tessdata\"'\n",
    "\n",
    "print(\"识别出的文字：\")\n",
    "print(text)\n",
    "\n",
    "# 保存OCR处理前后的图像\n",
    "cv2.imwrite(\"step4_original.jpg\", image)  # 保存原始扫描图像\n",
    "cv2.imwrite(\"step4_processed.jpg\", gray)  # 保存OCR预处理后的图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务 5: 多人脸检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('manyPeople.jpg') \n",
    "# 将彩色图像转换为灰度图像\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 加载面部检测分类器\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')  # 加载预训练的人脸检测分类器\n",
    "\n",
    "# 加载眼睛检测分类器\n",
    "\n",
    "\n",
    "# 检测灰度图像中的人脸\n",
    "\n",
    "\n",
    "print(\"发现{0}张人脸!\".format(len(faces)))  # 打印检测到的人脸数量\n",
    "print(\"其位置分别是：\")\n",
    "print(faces)  # 打印人脸的坐标和大小信息（x, y, w, h）\n",
    "\n",
    "for (x, y, w, h) in faces:  # 遍历检测到的每张人脸\n",
    "    # 在图像上绘制绿色的人脸矩形框\n",
    "\n",
    "\n",
    "    # 检测眼睛区域\n",
    "    \n",
    "\n",
    "    # 在人脸区域绘制蓝色的眼睛矩形框\n",
    "\n",
    "# 保存带有人脸和眼睛检测框的图像\n",
    "cv2.imwrite(\"face_result.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务 6: 基于 MeanShift 的目标跟踪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np\n",
    "\n",
    "# 打开视频文件\n",
    "cap = cv.VideoCapture(\"video.mp4\")\n",
    "\n",
    "# 设置初始跟踪窗口 (x, y, w, h)\n",
    "track_window = (800, 400, 200, 160)  \n",
    "ret, frame = cap.read()  # 读取视频的第一帧，ret 表示是否成功，frame 是图像数据\n",
    "x, y, w, h = track_window  \n",
    "\n",
    "# 提取初始区域并转换为 HSV 颜色空间\n",
    "\n",
    "\n",
    "mask = cv.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))  # 创建掩码，过滤特定颜色范围\n",
    "\n",
    "# 计算目标区域的色调直方图并归一化\n",
    "\n",
    "\n",
    "# 设置 MeanShift 终止条件为最大 10 次迭代或窗口移动小于 1 像素\n",
    "\n",
    "\n",
    "# 初始化视频写入对象\n",
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')  # 定义视频编码格式为 MP4V\n",
    "out = cv.VideoWriter(\"tracked_video.mp4\", fourcc, 30.0, (frame.shape[1], frame.shape[0]))  # 创建输出视频，帧率 30，尺寸与输入帧相同\n",
    "\n",
    "# 视频帧循环处理\n",
    "while True:\n",
    "    ret, frame = cap.read()  # 读取视频的下一帧\n",
    "    if ret:\n",
    "        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)  # 将当前帧转换为 HSV 颜色空间\n",
    "        # 根据目标直方图计算反投影图像\n",
    "\n",
    "\n",
    "        \n",
    "        x, y, w, h = track_window  # 获取更新后的窗口坐标和大小\n",
    "        img2 = cv.rectangle(frame, (x, y), (x+w, y+h), 255, 2)  # 在当前帧上绘制白色跟踪框，线宽为 2\n",
    "        out.write(img2)  # 将带跟踪框的帧写入输出视频\n",
    "    else:\n",
    "        break  # 如果帧读取失败（视频结束），退出循环\n",
    "\n",
    "# 释放资源\n",
    "cap.release() \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "好，那么好，你已经学会了拧螺丝，现在让我们开始造火箭吧：）\n",
    "\n",
    "#### 任务7: 修改任务6中的代码，提升跟踪效果\n",
    "- 问题：你已经注意到在视频后段，车辆的跟踪出现了漂移，效果变得不好了\n",
    "- 目标：修改代码，提高视频后段的跟踪效果\n",
    "- 提示：当前帧中直方图反应大部分区域发生变化时，剩下不变的区域就会被错误跟踪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 任务 8: 车道线检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv \n",
    "\n",
    "# 灰度图转换\n",
    "def grayscale(image):\n",
    "\n",
    "# Canny 边缘检测\n",
    "def canny(image, low_threshold, high_threshold):\n",
    "\n",
    "# 高斯滤波\n",
    "def gaussian_blur(image, kernel_size):\n",
    "\n",
    "# 生成兴趣区域即 Mask 掩模\n",
    "def region_of_interest(image, vertices):\n",
    "    mask = np.zeros_like(image)  # 创建与输入图像大小相同的零矩阵，作为掩模\n",
    "    if len(image.shape) > 2:  # 如果输入是彩色图像\n",
    "      \n",
    "      \n",
    "    else:  # 如果输入是灰度图像\n",
    "        ignore_mask_color = 255  # 设置填充颜色为白色（单通道）\n",
    "    \n",
    "    # 用白色填充多边形区域，生成掩模\n",
    "    cv.fillPoly(mask, vertices, ignore_mask_color)  \n",
    "    masked_image = cv.bitwise_and(image, mask)  # 与原图像进行位与运算，保留感兴趣区域\n",
    "    return masked_image\n",
    "\n",
    "# 霍夫变换检测直线\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    # rho: 距离精度，theta: 角度精度，threshold: 累加阈值\n",
    "    # min_line_len: 最小线段长度，max_line_gap: 最大断裂长度\n",
    "\n",
    "    return lines  # 返回检测到的线段，每条线段由起点和终点坐标表示\n",
    "\n",
    "# 绘制车道线\n",
    "def draw_lines(image, lines, color=[255,0,0], thickness=2):\n",
    "    right_y_set, right_x_set, right_slope_set = [], [], []  # 存储右车道线的 y 坐标、x 坐标和斜率\n",
    "    left_y_set, left_x_set, left_slope_set = [], [], []  # 存储左车道线的 y 坐标、x 坐标和斜率\n",
    "    slope_min, slope_max = 0.35, 0.85  # 定义车道线斜率的有效范围\n",
    "    middle_x = image.shape[1] / 2  # 计算图像水平中线位置\n",
    "    max_y = image.shape[0]  # 获取图像高度\n",
    "    for line in lines:  # 遍历所有检测到的线段\n",
    "        for x1, y1, x2, y2 in line:  # 提取线段的起点 (x1, y1) 和终点 (x2, y2)\n",
    "            fit = np.polyfit((x1, x2), (y1, y2), 1)  # 对线段进行一次多项式拟合\n",
    "            slope = fit[0]  # 获取斜率\n",
    "            if slope_min < np.absolute(slope) <= slope_max:  # 检查斜率是否在有效范围内\n",
    "                if slope > 0 and x1 > middle_x and x2 > middle_x:  # 判断为右车道线（正斜率且在图像右侧）\n",
    "                    right_y_set.extend([y1, y2])\n",
    "                    right_x_set.extend([x1, x2])\n",
    "                    right_slope_set.append(slope)\n",
    "                elif slope < 0 and x1 < middle_x and x2 < middle_x:  # 判断为左车道线（负斜率且在图像左侧）\n",
    "                    left_y_set.extend([y1, y2])\n",
    "                    left_x_set.extend([x1, x2])\n",
    "                    left_slope_set.append(slope)\n",
    "    # 绘制左车道线\n",
    "    if left_y_set:  # 如果检测到左车道线数据\n",
    "        lindex = left_y_set.index(min(left_y_set))  # 找到最高点（y 坐标最小）的索引\n",
    "        left_x_top, left_y_top = left_x_set[lindex], left_y_set[lindex]  # 获取顶部坐标\n",
    "        lslope = np.median(left_slope_set)  # 使用斜率中值提高稳定性\n",
    "        left_x_bottom = int(left_x_top + (max_y - left_y_top) / lslope)  # 根据斜率计算底部 x 坐标\n",
    "        cv.line(image, (left_x_bottom, max_y), (left_x_top, left_y_top), color, thickness)  # 绘制左车道线\n",
    "    # 绘制右车道线\n",
    "    if right_y_set:  # 如果检测到右车道线数据\n",
    "\n",
    "# 图像融合\n",
    "def weighted_img(img, initial_img, a=0.8, b=1., c=0.):\n",
    "\n",
    "# 主处理函数\n",
    "def process_image(image):\n",
    "    rho = 1  # 霍夫变换的距离精度（像素）\n",
    "    theta = np.pi / 180  # 霍夫变换的角度精度（1度）\n",
    "    hof_threshold = 20  # 霍夫变换的累加阈值\n",
    "    min_line_len = 30  # 霍夫变换检测的最小线段长度\n",
    "    max_line_gap = 60  # 霍夫变换允许的最大线段断裂长度\n",
    "    kernel_size = 5  # 高斯模糊的核大小\n",
    "    canny_low_threshold = 75  # Canny 边缘检测的低阈值\n",
    "    canny_high_threshold = canny_low_threshold * 3  # Canny 边缘检测的高阈值（低阈值的 3 倍）\n",
    "    alpha, beta, lambda_ = 0.8, 1., 0.  # 图像融合的权重参数\n",
    "    imshape = image.shape  # 获取输入图像的尺寸（高度、宽度、通道数）\n",
    "    # 灰度图转换\n",
    "\n",
    "    # 高斯滤波\n",
    "\n",
    "    # Canny 边缘检测\n",
    "\n",
    "    # 生成掩模区域\n",
    "    vertices = np.array([[(0, imshape[0]), (9 * imshape[1] / 20, 11 * imshape[0] / 18),\n",
    "                          (11 * imshape[1] / 20, 11 * imshape[0] / 18), (imshape[1], imshape[0])]], dtype=np.int32)\n",
    "    \n",
    "    masked_edges = region_of_interest(edge_image, vertices)  # 提取感兴趣区域，限制检测范围\n",
    "    # 霍夫变换检测直线\n",
    "\n",
    "    line_image = np.zeros_like(image)  # 创建与原图大小相同的空白图像，用于绘制车道线\n",
    "    # 绘制车道线\n",
    "\n",
    "    # 图像融合\n",
    "\n",
    "    return lines_edges  # 返回处理后的图像\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image = cv.imread('./test1.png')  \n",
    "    line_image = process_image(image)  # 调用主函数处理图像\n",
    "    cv.imwrite('line_img.jpg', line_image)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "恭喜你完成了本节课的所有练习。\n",
    "\n",
    "有同学问，助教助教，有没有更难点的题，我太闲了。\n",
    "\n",
    "有的同学有的！这还有两道附加题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 附加任务 1: SIFT 特征匹配与图像拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np \n",
    "\n",
    "def get_homo(img1, img2):\n",
    "    \"\"\"计算两幅图像之间的单应性矩阵\"\"\"\n",
    "    sift = cv.SIFT_create()  # 创建 SIFT 特征检测器，用于提取图像特征点\n",
    "    \n",
    "    # 提取图像的关键点和描述子\n",
    "    \n",
    "    # 在图像上绘制关键点并保存\n",
    "\n",
    "\n",
    "    \n",
    "    # 创建暴力匹配器，用于匹配两幅图像的特征点\n",
    "    bf = cv.BFMatcher()\n",
    "    \n",
    "    # 使用 KNN 算法匹配描述子，k=2 表示每个点找两个最近邻\n",
    "\n",
    "    \n",
    "    # 提取所有匹配对的第一个邻居\n",
    "    all_matches = [m[0] for m in matches]\n",
    "    \n",
    "    # 绘制所有匹配并保存结果\n",
    "\n",
    "\n",
    "    \n",
    "    # 筛选优质匹配，使用 Lowe's ratio test\n",
    "    verify_ratio = 0.8  # 匹配比率阈值，判断匹配质量\n",
    "    verify_matches = []\n",
    "    for m1, m2 in matches:\n",
    "        if m1.distance < verify_ratio * m2.distance:  # 如果第一个邻居距离小于第二个的 0.8 倍，则保留\n",
    "            verify_matches.append(m1)\n",
    "    \n",
    "    # 绘制优质匹配并保存\n",
    "    good_matches_img = cv.drawMatches(img1, k1, img2, k2, verify_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv.imwrite(\"sift_good_matches.jpg\", good_matches_img) \n",
    "    \n",
    "    # 检查匹配点数是否足够计算单应性矩阵\n",
    "    min_matches = 8  # 最小匹配点数要求\n",
    "    if len(verify_matches) > min_matches:\n",
    "        # 提取匹配点的坐标\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 使用 RANSAC 算法计算单应性矩阵\n",
    "\n",
    "        return H \n",
    "    else:\n",
    "        print(f\"Error: Insufficient matches ({len(verify_matches)} < {min_matches})\")  # 输出错误信息\n",
    "        exit()\n",
    "\n",
    "def stitch_image(img1, img2, H):\n",
    "    \"\"\"根据单应性矩阵拼接两幅图像\"\"\"\n",
    "    h1, w1 = img1.shape[:2]  \n",
    "    h2, w2 = img2.shape[:2]\n",
    "    \n",
    "    # 定义两幅图像的角点坐标\n",
    "    img1_dims = np.float32([[0,0], [0,h1-1], [w1-1,h1-1], [w1-1,0]]).reshape(-1,1,2) \n",
    "    img2_dims = np.float32([[0,0], [0,h2-1], [w2-1,h2-1], [w2-1,0]]).reshape(-1,1,2)\n",
    "    \n",
    "    # 对第一幅图像的角点应用单应性变换\n",
    "\n",
    "    result = np.concatenate([img2_dims, img1_transform], axis=0)  # 合并两幅图像的角点坐标\n",
    "    \n",
    "    [x_min, y_min] = np.int32(np.floor(result.min(axis=0).ravel())) \n",
    "    [x_max, y_max] = np.int32(np.ceil(result.max(axis=0).ravel())) \n",
    "    transform_dist = [-x_min, -y_min]  # 计算平移距离以避免负坐标\n",
    "    \n",
    "    # 创建平移矩阵，用于调整图像位置\n",
    "    transform_array = np.array([[1,0,transform_dist[0]], [0,1,transform_dist[1]], [0,0,1]])\n",
    "    \n",
    "    # 对第一幅图像应用透视变换并拼接第二幅图像\n",
    "\n",
    "    result_img[transform_dist[1]:transform_dist[1]+h2, transform_dist[0]-1:transform_dist[0]+w2] = img2\n",
    "    return result_img  # 返回拼接后的图像\n",
    "\n",
    "# 主程序\n",
    "images = []\n",
    "for i in range(3):\n",
    "    filename = 'image{}.JPG'.format(i+1)\n",
    "    img = cv.imread(filename)\n",
    "    img = cv.resize(img,(640,480))\n",
    "    images.append(img)\n",
    "\n",
    "for i in range(1, len(images)):\n",
    "    \n",
    "    \n",
    "    \n",
    "res = images[len(images)-1]\n",
    "cv.imwrite(\"stitched_image.jpg\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 附加任务 2: 细胞轮廓识别与编号标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "img = cv2.imread('count.jpg', 1)\n",
    "\n",
    "# 将彩色图像转换为灰度图像\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# 对灰度图像进行阈值处理，150 为阈值，255 为最大值，THRESH_BINARY_INV 表示反转二值化\n",
    "\n",
    "\n",
    "# 创建一个 5x5 的椭圆形结构元素，用于形态学操作\n",
    "\n",
    "\n",
    "# 使用腐蚀操作去除图像中的噪声\n",
    "\n",
    "\n",
    "# 对腐蚀后的图像进行膨胀\n",
    "\n",
    "\n",
    "# 使用 3x3 高斯核对图像进行模糊处理，平滑边缘，减少噪声影响\n",
    "\n",
    "\n",
    "# 检测图像中的轮廓\n",
    "\n",
    "\n",
    "contoursOK = [] \n",
    "for i in contours:  # 遍历所有检测到的轮廓\n",
    "    if cv2.contourArea(i) > 30:  # 如果轮廓面积大于 30，则认为是有意义的轮廓\n",
    "        contoursOK.append(i) \n",
    "\n",
    "# 在原图像上绘制绿色轮廓\n",
    "\n",
    "\n",
    "# 遍历筛选后的轮廓及其索引\n",
    "for i, j in zip(contoursOK, range(len(contoursOK))):\n",
    "    M = cv2.moments(i)  # 计算当前轮廓的矩，用于后续质心计算\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])  \n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    # 在质心位置标注轮廓的编号\n",
    "\n",
    "\n",
    "# 保存高斯模糊处理后的图像\n",
    "cv2.imwrite(\"gaussian.jpg\", gaussian)\n",
    "\n",
    "# 保存结果图像 'draw.jpg'\n",
    "cv2.imwrite(\"draw.jpg\", draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
