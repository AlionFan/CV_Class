{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c935525f",
   "metadata": {},
   "source": [
    "### 1.修改区域颜色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abc1b9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b234bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([125, 137, 226], dtype=uint8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('jupyter/lenacolor.png')\n",
    "img[0,0, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9728245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255, 255, 255], dtype=uint8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = img.copy()\n",
    "img1[0:50, 0:100, :] = [255, 255, 255]\n",
    "img1[50:100, 0:100, :] = [128, 128, 128]\n",
    "img1[100:150, 0:100, :] = [0, 0, 0]\n",
    "img1[150:200, 0:100, :] = [0, 0, 255]\n",
    "display(img1[0, 0, 0:3])\n",
    "# cv2.imshow('img1', img1)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "cv2.imwrite('result/task1/modified_lenacolor.png', img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d02f2",
   "metadata": {},
   "source": [
    "### 2. 读取彩色图片并创建掩码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b494158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('jupyter/x.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "mask = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "cv2.imwrite(\"result/task2/mask.png\", mask)\n",
    "cv2.imwrite('result/task2/gray_x.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef7c43",
   "metadata": {},
   "source": [
    "### 3.形态学操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e03151b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(\"jupyter/4.jpg\")\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imwrite(\"result/task3/open_4.jpg\", opening)\n",
    "\n",
    "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "cv2.imwrite(\"result/task3/tophat_4.jpg\", tophat)\n",
    "\n",
    "\n",
    "img = cv2.imread(\"jupyter/5.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "cv2.imwrite(\"result/task3/gradient_5.jpg\",gradient)\n",
    "\n",
    "\n",
    "img = cv2.imread(\"jupyter/6.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "close = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imwrite(\"result/task3/close_6.jpg\", close)\n",
    "\n",
    "blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "cv2.imwrite(\"result/task3/blackhat_6.jpg\", blackhat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174916a5",
   "metadata": {},
   "source": [
    "### 4.图像透视变换与 OCR 文字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2cece6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: 边缘检测\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 19:31:54.479 Python[34638:894479] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-25 19:31:54.479 Python[34638:894479] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: 获取轮廓\n",
      "STEP 3: 变换\n",
      "STEP 4: 文字提取\n",
      "提取的文字内容：\n",
      "x oe Ke KR Re KR KK KR Ke KH KK\n",
      "\n",
      "WH\n",
      "FOODS\n",
      "\n",
      "WHOLE FOODS MARKET\n",
      "\n",
      "399 POST RD WEST\n",
      "\n",
      "36u\n",
      "365\n",
      "365\n",
      "\n",
      "365\n",
      "\n",
      "BROTH\n",
      "\n",
      "OLE\n",
      "DS\n",
      "\n",
      "WESTPORT, CT 06880\n",
      "(203) 227-6858\n",
      "\n",
      "BACUN\n",
      "BACON\n",
      "BACON\n",
      "BACUN\n",
      "\n",
      "Vv\n",
      "\n",
      "mw WH\n",
      "\n",
      "re\n",
      "\n",
      "CHIC\n",
      "\n",
      "FLOUR ALMUND\n",
      "CHKN BRST BNLSS SK\n",
      "HEAVY CREAM\n",
      "BALSMC REDUCT\n",
      "\n",
      "BEEF\n",
      "\n",
      "DOCS\n",
      "\n",
      "GRND\n",
      "JUICE COF CASHEW\n",
      "PINT ORGAHIE\n",
      "\n",
      "85/15\n",
      "\n",
      "HNY ALMOND BuiTeR\n",
      "\n",
      "关关关头 TAX\n",
      "\n",
      ".00\n",
      "\n",
      "BAL\n",
      "\n",
      "4 99\n",
      "4.99\n",
      "4.99\n",
      "4 99\n",
      "2.15\n",
      "1.99\n",
      "8.80\n",
      "3.39\n",
      "6.49\n",
      "5.04\n",
      "8.99\n",
      "14.49\n",
      "\n",
      "9.99\n",
      "101.33\n",
      "\n",
      "Tr\n",
      "\n",
      "cae a)     T\n",
      "\n",
      "manna 4\n",
      "\n",
      "v\"T\n",
      "\n",
      "Tn TT\n",
      "\n",
      "\n",
      "文字已保存到 result/task4/extracted_text.txt\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 导入工具包\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def order_points(pts):\n",
    "\t# 一共4个坐标点\n",
    "\trect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "\t# 按顺序找到对应坐标0123分别是 左上，右上，右下，左下\n",
    "\t# 计算左上，右下\n",
    "\ts = pts.sum(axis = 1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\n",
    "\t# 计算右上和左下\n",
    "\tdiff = np.diff(pts, axis = 1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "\treturn rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "\t# 获取输入坐标点\n",
    "\trect = order_points(pts)\n",
    "\t(tl, tr, br, bl) = rect\n",
    "\n",
    "\t# 计算输入的w和h值\n",
    "\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\tmaxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\tmaxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "\t# 变换后对应坐标位置\n",
    "\tdst = np.array([\n",
    "\t\t[0, 0],\n",
    "\t\t[maxWidth - 1, 0],\n",
    "\t\t[maxWidth - 1, maxHeight - 1],\n",
    "\t\t[0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "\t# 计算变换矩阵\n",
    "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
    "\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "\t# 返回变换后结果\n",
    "\treturn warped\n",
    "\n",
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "\tdim = None\n",
    "\t(h, w) = image.shape[:2]\n",
    "\tif width is None and height is None:\n",
    "\t\treturn image\n",
    "\tif width is None:\n",
    "\t\tr = height / float(h)\n",
    "\t\tdim = (int(w * r), height)\n",
    "\telse:\n",
    "\t\tr = width / float(w)\n",
    "\t\tdim = (width, int(h * r))\n",
    "\tresized = cv2.resize(image, dim, interpolation=inter)\n",
    "\treturn resized\n",
    "\n",
    "# 读取输入\n",
    "image = cv2.imread(\"jupyter/receipt.jpg\")\n",
    "#坐标也会相同变化\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "\n",
    "\n",
    "image = resize(orig, height = 500)\n",
    "\n",
    "# 预处理\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 75, 200)\n",
    "\n",
    "# 展示预处理结果\n",
    "print(\"STEP 1: 边缘检测\")\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.imwrite(\"result/task4/edged.jpg\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 轮廓检测\n",
    "cnts, _ = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "# 遍历轮廓\n",
    "for c in cnts:\n",
    "\t# 计算轮廓近似\n",
    "\tperi = cv2.arcLength(c, True)\n",
    "\t# C表示输入的点集\n",
    "\t# epsilon表示从原始轮廓到近似轮廓的最大距离，它是一个准确度参数\n",
    "\t# True表示封闭的\n",
    "\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "\t# 4个点的时候就拿出来\n",
    "\tif len(approx) == 4:\n",
    "\t\tscreenCnt = approx\n",
    "\t\tbreak\n",
    "\n",
    "# 展示结果\n",
    "print(\"STEP 2: 获取轮廓\")\n",
    "cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "cv2.imwrite(\"result/task4/outline.jpg\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 透视变换\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "\n",
    "# 二值处理\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "ref = cv2.threshold(warped, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "cv2.imwrite('result/task4/scan.jpg', ref)\n",
    "\n",
    "# 展示结果\n",
    "print(\"STEP 3: 变换\")\n",
    "cv2.imshow(\"Original\", resize(orig, height = 650))\n",
    "cv2.imshow(\"Scanned\", resize(ref, height = 650))\n",
    "cv2.imwrite(\"result/task4/orig.jpg\", orig)\n",
    "cv2.imwrite(\"result/task4/ref.jpg\", ref)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# 文字提取\n",
    "print(\"STEP 4: 文字提取\")\n",
    "# 对图像进行额外的预处理以提高文字识别效果\n",
    "kernel = np.ones((2,2), np.uint8)\n",
    "ref = cv2.dilate(ref, kernel, iterations=1)\n",
    "ref = cv2.erode(ref, kernel, iterations=1)\n",
    "\n",
    "# 将OpenCV图像转换为PIL图像\n",
    "pil_image = Image.fromarray(ref)\n",
    "\n",
    "# 使用pytesseract提取文字\n",
    "text = pytesseract.image_to_string(pil_image, lang='chi_sim+eng')\n",
    "\n",
    "# 将提取的文字保存到文件\n",
    "with open('result/task4/extracted_text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"提取的文字内容：\")\n",
    "print(text)\n",
    "print(\"\\n文字已保存到 result/task4/extracted_text.txt\")\n",
    "\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd0f54",
   "metadata": {},
   "source": [
    "### 5.多人脸检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4a7d4e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发现11张人脸!\n",
      "其位置分别是：\n",
      "[[  97   99  169  169]\n",
      " [1147  104  160  160]\n",
      " [ 843  200   70   70]\n",
      " [ 888  104  167  167]\n",
      " [ 361   96  166  166]\n",
      " [ 623  101  162  162]\n",
      " [  99  375  160  160]\n",
      " [ 884  373  161  161]\n",
      " [1142  369  167  167]\n",
      " [ 357  373  165  165]\n",
      " [ 626  383  151  151]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('jupyter/manyPeople.jpg') \n",
    "# 将彩色图像转换为灰度图像\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 加载面部检测分类器\n",
    "faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')  # 加载预训练的人脸检测分类器\n",
    "\n",
    "# 加载眼睛检测分类器\n",
    "eyeCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')  # 加载预训练的眼睛检测分类器\n",
    "\n",
    "# 检测灰度图像中的人脸\n",
    "faces = faceCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "print(\"发现{0}张人脸!\".format(len(faces)))  # 打印检测到的人脸数量\n",
    "print(\"其位置分别是：\")\n",
    "print(faces)  # 打印人脸的坐标和大小信息（x, y, w, h）\n",
    "\n",
    "for (x, y, w, h) in faces:  # 遍历检测到的每张人脸\n",
    "    # 在图像上绘制绿色的人脸矩形框\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    # 检测眼睛区域\n",
    "    eyes = eyeCascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # 在人脸区域绘制蓝色的眼睛矩形框\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(image, (ex, ey), (ex + ew, ey + eh), (0, 0, 255), 2)\n",
    "\n",
    "# 保存带有人脸和眼睛检测框的图像\n",
    "cv2.imwrite(\"result/task5/face_result.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508eb06",
   "metadata": {},
   "source": [
    "### 6.基于 MeanShift 的目标跟踪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "38db365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np\n",
    "\n",
    "# 打开视频文件\n",
    "cap = cv.VideoCapture(\"jupyter/video.mp4\")\n",
    "\n",
    "# 设置初始跟踪窗口 (x, y, w, h)\n",
    "track_window = (800, 400, 200, 160)  \n",
    "ret, frame = cap.read()  # 读取视频的第一帧，ret 表示是否成功，frame 是图像数据\n",
    "x, y, w, h = track_window  \n",
    "\n",
    "# 提取初始区域并转换为 HSV 颜色空间\n",
    "hsv_roi = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "\n",
    "mask = cv.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))  # 创建掩码，过滤特定颜色范围\n",
    "\n",
    "# 计算目标区域的色调直方图并归一化\n",
    "roi_hist = cv.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "cv.normalize(roi_hist, roi_hist, 0, 255, cv.NORM_MINMAX)\n",
    "\n",
    "# 设置 MeanShift 终止条件为最大 10 次迭代或窗口移动小于 1 像素\n",
    "termcriteria = (cv.TERM_CRITERIA_COUNT | cv.TERM_CRITERIA_EPS, 10, 1)\n",
    "\n",
    "\n",
    "# 初始化视频写入对象\n",
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')  # 定义视频编码格式为 MP4V\n",
    "out = cv.VideoWriter(\"result/task6/tracked_video.mp4\", fourcc, 30.0, (frame.shape[1], frame.shape[0]))  # 创建输出视频，帧率 30，尺寸与输入帧相同\n",
    "\n",
    "# 视频帧循环处理\n",
    "while True:\n",
    "    ret, frame = cap.read()  # 读取视频的下一帧\n",
    "    if ret:\n",
    "        hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)  # 将当前帧转换为 HSV 颜色空间\n",
    "        # 根据目标直方图计算反投影图像\n",
    "        dst = cv.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "        # 应用 MeanShift 跟踪\n",
    "        ret, track_window = cv.meanShift(dst, track_window, termcriteria)\n",
    "        \n",
    "        x, y, w, h = track_window  # 获取更新后的窗口坐标和大小\n",
    "        img2 = cv.rectangle(frame, (x, y), (x+w, y+h), 255, 2)  # 在当前帧上绘制白色跟踪框，线宽为 2\n",
    "        out.write(img2)  # 将带跟踪框的帧写入输出视频\n",
    "    else:\n",
    "        break  # 如果帧读取失败（视频结束），退出循环\n",
    "\n",
    "# 释放资源\n",
    "cap.release() \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060669d4",
   "metadata": {},
   "source": [
    "### 7.改进"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "def main():\n",
    "\t# 打开视频文件\n",
    "\tvs = cv2.VideoCapture(\"jupyter/video.mp4\")\n",
    "\n",
    "\t# 获取视频的第一帧\n",
    "\tret, first_frame = vs.read()\n",
    "\tif ret:\n",
    "\t\t# 设置初始追踪区域（使用原始坐标，不进行缩放）\n",
    "\t\tx, y, w, h = 800, 400, 200, 160\n",
    "\t\t\n",
    "\t\t# 获取原始视频尺寸\n",
    "\t\t(height, width) = first_frame.shape[:2]\n",
    "\t\t\n",
    "\t\t# 创建dlib追踪器\n",
    "\t\ttracker = dlib.correlation_tracker()\n",
    "\t\trect = dlib.rectangle(x, y, x + w, y + h)\n",
    "\t\trgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "\t\ttracker.start_track(rgb, rect)\n",
    "\t\t\n",
    "\t\t# 设置输出视频（使用原始尺寸）\n",
    "\t\tfourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\t\tout = cv2.VideoWriter(\"result/task7/dlib_tracked.mp4\", fourcc, 30.0, (width, height))\n",
    "\n",
    "\t\t# 视频流\n",
    "\t\twhile True:\n",
    "\t\t\t# 读取当前帧\n",
    "\t\t\tret, frame = vs.read()\n",
    "\t\t\tif not ret:\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\t# 转换颜色空间用于追踪\n",
    "\t\t\trgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\t\t\t\n",
    "\t\t\t# 更新追踪器\n",
    "\t\t\ttracker.update(rgb)\n",
    "\t\t\tpos = tracker.get_position()\n",
    "\t\t\t\n",
    "\t\t\t# 获取追踪框坐标\n",
    "\t\t\tstartX = int(pos.left())\n",
    "\t\t\tstartY = int(pos.top())\n",
    "\t\t\tendX = int(pos.right())\n",
    "\t\t\tendY = int(pos.bottom())\n",
    "\t\t\t\n",
    "\t\t\t# 绘制追踪框\n",
    "\t\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\t\t\tcv2.putText(frame, \"Tracking\", (startX, startY - 10), \n",
    "\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\t\t\t\n",
    "\t\t\t# 写入输出视频\n",
    "\t\t\tout.write(frame)\n",
    "\t\t\t\n",
    "\t\t\t# 按ESC退出\n",
    "\t\t\tif cv2.waitKey(100) & 0xFF == 27:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t# 释放资源\n",
    "\tvs.release()\n",
    "\tout.release()\n",
    "\tcv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cc7d2a",
   "metadata": {},
   "source": [
    "### 8. 车道线检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd45fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv \n",
    "\n",
    "# 灰度图转换\n",
    "def grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "# Canny 边缘检测\n",
    "def canny(image, low_threshold, high_threshold):\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "# 高斯滤波\n",
    "def gaussian_blur(image, kernel_size):\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "# 生成兴趣区域即 Mask 掩模\n",
    "def region_of_interest(image, vertices):\n",
    "    mask = np.zeros_like(image)  # 创建与输入图像大小相同的零矩阵，作为掩模\n",
    "    if len(image.shape) > 2:  # 如果输入是彩色图像\n",
    "        ignore_mask_color = (255,) * image.shape[2]  # 设置填充颜色为白色（多通道）\n",
    "      \n",
    "    else:  # 如果输入是灰度图像\n",
    "        ignore_mask_color = 255  # 设置填充颜色为白色（单通道）\n",
    "    \n",
    "    # 用白色填充多边形区域，生成掩模\n",
    "    cv.fillPoly(mask, vertices, ignore_mask_color)  \n",
    "    masked_image = cv.bitwise_and(image, mask)  # 与原图像进行位与运算，保留感兴趣区域\n",
    "    return masked_image\n",
    "\n",
    "# 霍夫变换检测直线\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    # rho: 距离精度，theta: 角度精度，threshold: 累加阈值\n",
    "    # min_line_len: 最小线段长度，max_line_gap: 最大断裂长度\n",
    "    lines = cv.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    return lines  # 返回检测到的线段，每条线段由起点和终点坐标表示\n",
    "\n",
    "# 绘制车道线\n",
    "def draw_lines(image, lines, color=[255,0,0], thickness=2):\n",
    "    right_y_set, right_x_set, right_slope_set = [], [], []  # 存储右车道线的 y 坐标、x 坐标和斜率\n",
    "    left_y_set, left_x_set, left_slope_set = [], [], []  # 存储左车道线的 y 坐标、x 坐标和斜率\n",
    "    slope_min, slope_max = 0.35, 0.85  # 定义车道线斜率的有效范围\n",
    "    middle_x = image.shape[1] / 2  # 计算图像水平中线位置\n",
    "    max_y = image.shape[0]  # 获取图像高度\n",
    "    for line in lines:  # 遍历所有检测到的线段\n",
    "        for x1, y1, x2, y2 in line:  # 提取线段的起点 (x1, y1) 和终点 (x2, y2)\n",
    "            fit = np.polyfit((x1, x2), (y1, y2), 1)  # 对线段进行一次多项式拟合\n",
    "            slope = fit[0]  # 获取斜率\n",
    "            if slope_min < np.absolute(slope) <= slope_max:  # 检查斜率是否在有效范围内\n",
    "                if slope > 0 and x1 > middle_x and x2 > middle_x:  # 判断为右车道线（正斜率且在图像右侧）\n",
    "                    right_y_set.extend([y1, y2])\n",
    "                    right_x_set.extend([x1, x2])\n",
    "                    right_slope_set.append(slope)\n",
    "                elif slope < 0 and x1 < middle_x and x2 < middle_x:  # 判断为左车道线（负斜率且在图像左侧）\n",
    "                    left_y_set.extend([y1, y2])\n",
    "                    left_x_set.extend([x1, x2])\n",
    "                    left_slope_set.append(slope)\n",
    "    # 绘制左车道线\n",
    "    if left_y_set:  # 如果检测到左车道线数据\n",
    "        lindex = left_y_set.index(min(left_y_set))  # 找到最高点（y 坐标最小）的索引\n",
    "        left_x_top, left_y_top = left_x_set[lindex], left_y_set[lindex]  # 获取顶部坐标\n",
    "        lslope = np.median(left_slope_set)  # 使用斜率中值提高稳定性\n",
    "        left_x_bottom = int(left_x_top + (max_y - left_y_top) / lslope)  # 根据斜率计算底部 x 坐标\n",
    "        cv.line(image, (left_x_bottom, max_y), (left_x_top, left_y_top), color, thickness)  # 绘制左车道线\n",
    "    # 绘制右车道线\n",
    "    if right_y_set:  # 如果检测到右车道线数据\n",
    "        rindex = right_y_set.index(min(right_y_set))  # 找到最高点（y 坐标最小）的索引\n",
    "        right_x_top, right_y_top = right_x_set[rindex], right_y_set[rindex]  # 获取顶部坐标\n",
    "        rslope = np.median(right_slope_set)  # 使用斜率中值提高稳定性\n",
    "        right_x_bottom = int(right_x_top + (max_y - right_y_top) / rslope)  # 根据斜率计算底部 x 坐标\n",
    "        cv.line(image, (right_x_bottom, max_y), (right_x_top, right_y_top), color, thickness)  # 绘制右车道线\n",
    "    return image  # 返回绘制车道线的图像\n",
    "\n",
    "# 图像融合\n",
    "def weighted_img(img, initial_img, a=0.8, b=1., c=0.):\n",
    "    return cv2.addWeighted(initial_img, a, img, b, c)\n",
    "# 主处理函数\n",
    "def process_image(image):\n",
    "    rho = 1  # 霍夫变换的距离精度（像素）\n",
    "    theta = np.pi / 180  # 霍夫变换的角度精度（1度）\n",
    "    hof_threshold = 20  # 霍夫变换的累加阈值\n",
    "    min_line_len = 30  # 霍夫变换检测的最小线段长度\n",
    "    max_line_gap = 60  # 霍夫变换允许的最大线段断裂长度\n",
    "    kernel_size = 5  # 高斯模糊的核大小\n",
    "    canny_low_threshold = 75  # Canny 边缘检测的低阈值\n",
    "    canny_high_threshold = canny_low_threshold * 3  # Canny 边缘检测的高阈值（低阈值的 3 倍）\n",
    "    alpha, beta, lambda_ = 0.8, 1., 0.  # 图像融合的权重参数\n",
    "    imshape = image.shape  # 获取输入图像的尺寸（高度、宽度、通道数）\n",
    "    # 灰度图转换\n",
    "    gray = grayscale(image)\n",
    "    # 高斯滤波\n",
    "    blur_gray = gaussian_blur(gray, kernel_size)\n",
    "    # Canny 边缘检测\n",
    "    edge_image = canny(blur_gray, canny_low_threshold, canny_high_threshold)\n",
    "    # 生成掩模区域\n",
    "    vertices = np.array([[(0, imshape[0]), (9 * imshape[1] / 20, 11 * imshape[0] / 18),\n",
    "                          (11 * imshape[1] / 20, 11 * imshape[0] / 18), (imshape[1], imshape[0])]], dtype=np.int32)\n",
    "    \n",
    "    masked_edges = region_of_interest(edge_image, vertices)  # 提取感兴趣区域，限制检测范围\n",
    "    # 霍夫变换检测直线\n",
    "    lines = hough_lines(masked_edges, rho, theta, hof_threshold, min_line_len, max_line_gap)\n",
    "    line_image = np.zeros_like(image)  # 创建与原图大小相同的空白图像，用于绘制车道线\n",
    "    # 绘制车道线\n",
    "    line_image = draw_lines(line_image, lines)\n",
    "    # 图像融合\n",
    "    lines_edges = weighted_img(line_image, image, alpha, beta, lambda_)\n",
    "\n",
    "    return lines_edges  # 返回处理后的图像\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image = cv.imread('jupyter/test1.png')  \n",
    "    line_image = process_image(image)  # 调用主函数处理图像\n",
    "    cv.imwrite('result/task8/resultline_img.jpg', line_image)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e07c3",
   "metadata": {},
   "source": [
    "### 附加实验1: SIFT 特征匹配与图像拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e54b004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np \n",
    "\n",
    "def get_homo(img1, img2):\n",
    "    \"\"\"计算两幅图像之间的单应性矩阵\"\"\"\n",
    "    sift = cv.SIFT_create()  # 创建 SIFT 特征检测器，用于提取图像特征点\n",
    "    \n",
    "    # 提取图像的关键点和描述子\n",
    "    k1, des1 = sift.detectAndCompute(img1, None)\n",
    "    k2, des2 = sift.detectAndCompute(img2, None)\n",
    "    \n",
    "    # 在图像上绘制关键点并保存\n",
    "    img1_keypoints = cv.drawKeypoints(img1, k1, None)\n",
    "    cv.imwrite(\"result/task_add_1/sift_keypoints.jpg\", img1_keypoints)\n",
    "\n",
    "    # 创建暴力匹配器，用于匹配两幅图像的特征点\n",
    "    bf = cv.BFMatcher()\n",
    "    \n",
    "    # 使用 KNN 算法匹配描述子，k=2 表示每个点找两个最近邻\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    # 提取所有匹配对的第一个邻居\n",
    "    all_matches = [m[0] for m in matches]\n",
    "    \n",
    "    # 绘制所有匹配并保存结果\n",
    "    match_img = cv.drawMatches(img1, k1, img2, k2, all_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv.imwrite(\"result/task_add_1/sift_matches.jpg\", match_img)\n",
    "\n",
    "    # 筛选优质匹配，使用 Lowe's ratio test\n",
    "    verify_ratio = 0.8  # 匹配比率阈值，判断匹配质量\n",
    "    verify_matches = []\n",
    "    for m1, m2 in matches:\n",
    "        if m1.distance < verify_ratio * m2.distance:  # 如果第一个邻居距离小于第二个的 0.8 倍，则保留\n",
    "            verify_matches.append(m1)\n",
    "    \n",
    "    # 绘制优质匹配并保存\n",
    "    good_matches_img = cv.drawMatches(img1, k1, img2, k2, verify_matches, None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv.imwrite(\"result/task_add_1/sift_good_matches.jpg\", good_matches_img) \n",
    "    \n",
    "    # 检查匹配点数是否足够计算单应性矩阵\n",
    "    min_matches = 8  # 最小匹配点数要求\n",
    "    if len(verify_matches) > min_matches:\n",
    "        # 提取匹配点的坐标\n",
    "        img1_pts = np.float32([k1[m.queryIdx].pt for m in verify_matches]).reshape(-1, 2)\n",
    "        img2_pts = np.float32([k2[m.trainIdx].pt for m in verify_matches]).reshape(-1, 2)\n",
    "\n",
    "        # 使用 RANSAC 算法计算单应性矩阵\n",
    "        H, _ = cv.findHomography(img1_pts, img2_pts, cv.RANSAC, 5.0)\n",
    "        return H \n",
    "    else:\n",
    "        print(f\"Error: Insufficient matches ({len(verify_matches)} < {min_matches})\")  # 输出错误信息\n",
    "        exit()\n",
    "\n",
    "def stitch_image(img1, img2, H):\n",
    "    \"\"\"根据单应性矩阵拼接两幅图像\"\"\"\n",
    "    h1, w1 = img1.shape[:2]  \n",
    "    h2, w2 = img2.shape[:2]\n",
    "    \n",
    "    # 定义两幅图像的角点坐标\n",
    "    img1_dims = np.float32([[0,0], [0,h1-1], [w1-1,h1-1], [w1-1,0]]).reshape(-1,1,2) \n",
    "    img2_dims = np.float32([[0,0], [0,h2-1], [w2-1,h2-1], [w2-1,0]]).reshape(-1,1,2)\n",
    "    \n",
    "    # 对第一幅图像的角点应用单应性变换\n",
    "    img1_transform = cv.perspectiveTransform(img1_dims, H)\n",
    "    result = np.concatenate([img2_dims, img1_transform], axis=0)  # 合并两幅图像的角点坐标\n",
    "    \n",
    "    [x_min, y_min] = np.int32(np.floor(result.min(axis=0).ravel())) \n",
    "    [x_max, y_max] = np.int32(np.ceil(result.max(axis=0).ravel())) \n",
    "    transform_dist = [-x_min, -y_min]  # 计算平移距离以避免负坐标\n",
    "    \n",
    "    # 创建平移矩阵，用于调整图像位置\n",
    "    transform_array = np.array([[1,0,transform_dist[0]], [0,1,transform_dist[1]], [0,0,1]])\n",
    "    \n",
    "    # 组合单应性矩阵和平移矩阵\n",
    "    output_shape = (x_max-x_min, y_max-y_min)\n",
    "    H_output = transform_array @ H\n",
    "    \n",
    "    # 对第一幅图像应用透视变换并拼接第二幅图像\n",
    "    result_img = cv.warpPerspective(img1, H_output, output_shape)\n",
    "    result_img[transform_dist[1]:transform_dist[1]+h2, transform_dist[0]:transform_dist[0]+w2] = img2\n",
    "    return result_img  # 返回拼接后的图像\n",
    "\n",
    "# 主程序\n",
    "images = []\n",
    "for i in range(3):\n",
    "    filename = 'jupyter/image{}.jpg'.format(i+1)\n",
    "    img = cv.imread(filename)\n",
    "    img = cv.resize(img,(640,480))\n",
    "    images.append(img)\n",
    "\n",
    "for i in range(1, len(images)):\n",
    "    H = get_homo(images[i], images[i-1])\n",
    "    images[i] = stitch_image(images[i], images[i-1], H)\n",
    "    \n",
    "    \n",
    "res = images[len(images)-1]\n",
    "cv.imwrite(\"result/task_add_1/stitched_image.jpg\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46122f7",
   "metadata": {},
   "source": [
    "### 附加实验2: 细胞轮廓识别与编号标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ca743d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2  \n",
    "img = cv2.imread('jupyter/count.jpg', 1)\n",
    "\n",
    "# 将彩色图像转换为灰度图像\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# 对灰度图像进行阈值处理，150 为阈值，255 为最大值，THRESH_BINARY_INV 表示反转二值化\n",
    "_, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# 创建一个 5x5 的椭圆形结构元素，用于形态学操作\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "# 使用腐蚀操作去除图像中的噪声\n",
    "eroded = cv2.erode(binary, kernel, iterations=4)\n",
    "\n",
    "# 对腐蚀后的图像进行膨胀\n",
    "dilated = cv2.dilate(eroded, kernel, iterations=2)\n",
    "\n",
    "# 使用 3x3 高斯核对图像进行模糊处理，平滑边缘，减少噪声影响\n",
    "gaussian = cv2.GaussianBlur(dilated, (3, 3), 0)\n",
    "\n",
    "# 检测图像中的轮廓\n",
    "contours, _ = cv2.findContours(gaussian, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "contoursOK = [] \n",
    "for i in contours:  # 遍历所有检测到的轮廓\n",
    "    if cv2.contourArea(i) > 30:  # 如果轮廓面积大于 30，则认为是有意义的轮廓\n",
    "        contoursOK.append(i) \n",
    "\n",
    "# 在原图像上绘制绿色轮廓\n",
    "draw = cv2.drawContours(img, contoursOK, -1, (0, 255, 0), 2)\n",
    "\n",
    "# 遍历筛选后的轮廓及其索引\n",
    "for i, j in zip(contoursOK, range(len(contoursOK))):\n",
    "    M = cv2.moments(i)  # 计算当前轮廓的矩，用于后续质心计算\n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])  \n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    # 在质心位置标注轮廓的编号\n",
    "    cv2.putText(img, str(j), (cX, cY), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 2)\n",
    "\n",
    "# 保存高斯模糊处理后的图像\n",
    "cv2.imwrite(\"result/task_add_2/gaussian.jpg\", gaussian)\n",
    "\n",
    "# 保存结果图像 'draw.jpg'\n",
    "cv2.imwrite(\"result/task_add_2/draw.jpg\", draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43985965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
